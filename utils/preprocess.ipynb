{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.dataloader import load_subject_labels\n",
    "\n",
    "wd = '/Volumes/Guillaume EEG Project'\n",
    "epoch_data_path = os.path.join(wd, 'Berlin_Data/EEG/preprocessed/stim_epochs_incl_response')\n",
    "raw_data_path = os.path.join(wd, 'Berlin_Data/EEG/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Volumes/Guillaume EEG Project/Berlin_Data/EEG/raw/9/9.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from /Volumes/Guillaume EEG Project/Berlin_Data/EEG/raw/9/9_2.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from /Volumes/Guillaume EEG Project/Berlin_Data/EEG/raw/9/9_3.vhdr...\n",
      "Setting channel info structure...\n",
      "     response  confidence  choice_rt  correct  session  run\n",
      "0         NaN         NaN        NaN      NaN        1    4\n",
      "1         1.0         2.0   0.684519      1.0        1    4\n",
      "2         1.0         2.0   0.218998      1.0        1    4\n",
      "3         1.0         2.0   0.282629      1.0        1    4\n",
      "4         NaN         NaN        NaN      NaN        1    4\n",
      "..        ...         ...        ...      ...      ...  ...\n",
      "348       1.0         2.0   1.199172      0.0        1    1\n",
      "349      -1.0         2.0   0.538509      1.0        1    1\n",
      "350       1.0         2.0   1.339938      0.0        1    1\n",
      "351      -1.0         2.0   2.157726      1.0        1    1\n",
      "352       NaN         NaN        NaN      NaN        1    1\n",
      "\n",
      "[353 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "subject_id = 9\n",
    "\n",
    "raws = []\n",
    "for file in [os.path.join(wd, raw_data_path, '{}/{}{}.vhdr'.format(subject_id, subject_id, suffix)) for suffix in ['', '_2', '_3', '_4', '_5']]:\n",
    "    if os.path.isfile(file):\n",
    "        raw = mne.io.read_raw_brainvision(file)\n",
    "        raws.append(raw)\n",
    "\n",
    "behav_data = load_subject_labels(os.path.join(wd, raw_data_path), subject_id=subject_id)\n",
    "\n",
    "print(behav_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## SPLIT RAW INTO BLOCKS\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Specify the annotation type you want to use for splitting\u001B[39;00m\n\u001B[1;32m      3\u001B[0m split_annotation_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStimulus/S105\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m raw_segments \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m raw \u001B[38;5;129;01min\u001B[39;00m raws:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# Find the onset times of the relevant annotations\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     split_onsets \u001B[38;5;241m=\u001B[39m [annot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124monset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m annot \u001B[38;5;129;01min\u001B[39;00m raw\u001B[38;5;241m.\u001B[39mannotations \u001B[38;5;28;01mif\u001B[39;00m annot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m split_annotation_type]\n",
      "Cell \u001B[0;32mIn[15], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m## SPLIT RAW INTO BLOCKS\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Specify the annotation type you want to use for splitting\u001B[39;00m\n\u001B[1;32m      3\u001B[0m split_annotation_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStimulus/S105\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m raw_segments \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m raw \u001B[38;5;129;01min\u001B[39;00m raws:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# Find the onset times of the relevant annotations\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     split_onsets \u001B[38;5;241m=\u001B[39m [annot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124monset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m annot \u001B[38;5;129;01min\u001B[39;00m raw\u001B[38;5;241m.\u001B[39mannotations \u001B[38;5;28;01mif\u001B[39;00m annot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdescription\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m split_annotation_type]\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:747\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 747\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1155\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1152\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1170\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1167\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1170\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "## SPLIT RAW INTO BLOCKS\n",
    "# Specify the annotation type you want to use for splitting\n",
    "split_annotation_type = 'Stimulus/S105'\n",
    "\n",
    "raw_segments = []\n",
    "for raw in raws:\n",
    "    # Find the onset times of the relevant annotations\n",
    "    split_onsets = [annot['onset'] for annot in raw.annotations if annot['description'] == split_annotation_type]\n",
    "\n",
    "    # Sort the onsets and add the start and end times of the raw object for splitting\n",
    "    split_onsets = split_onsets + [raw.times[-1]]\n",
    "\n",
    "    # Iterate over consecutive pairs of split points to create new raw segments\n",
    "    for start, end in zip(split_onsets[:-1], split_onsets[1:]):\n",
    "        raw_segment = raw.copy().crop(tmin=start, tmax=end, include_tmax=False)\n",
    "        raw_segments.append(raw_segment)\n",
    "\n",
    "# Now raw_segments is a list of mne.io.Raw objects split at the specified annotations\n",
    "print(len(raw_segments))\n",
    "\n",
    "for i, seg in enumerate(raw_segments):\n",
    "    print('---------------{}---------------'.format(i+1))\n",
    "    print(seg)\n",
    "    trial_n = pd.Series(seg.annotations.description).value_counts()['Stimulus/S151']\n",
    "    print(seg.info['meas_date'])\n",
    "    print('{} trials'.format(trial_n))\n",
    "    print('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# TODO: will need to select correct segments and correct behavioural data.\n",
    "#       Don't know if this will work in an automated fashion, otherwise compare everything by eye...\n",
    "raw_segments = raw_segments[1:]\n",
    "print(len(raw_segments))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of 'Stimulus/S 48' annotations does not match the number of rows in the DataFrame.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(stimulus_onsets) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(df):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStimulus/S 48\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m annotations does not match the number of rows in the DataFrame.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Step 3: Create new annotations based on the reaction times in the DataFrame\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m onset, choice_rt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(stimulus_onsets, df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoice_rt\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n",
      "\u001B[0;31mValueError\u001B[0m: The number of 'Stimulus/S 48' annotations does not match the number of rows in the DataFrame."
     ]
    }
   ],
   "source": [
    "## CREATE NEW ANNOTATIONS FOR RESPONSE TIMES\n",
    "for i, seg in enumerate(raw_segments):\n",
    "    df = behav_data[behav_data['run'] == i + 1]\n",
    "\n",
    "    # Step 1: Extract the onsets of 'Stimulus/S 48' annotations\n",
    "    stimulus_onsets = [annot['onset'] for annot in seg.annotations if annot['description'] == 'Stimulus/S 48']\n",
    "\n",
    "    # Step 2: Ensure the number of onsets matches the number of rows in the DataFrame\n",
    "    if len(stimulus_onsets) != len(df):\n",
    "        raise ValueError(\"The number of 'Stimulus/S 48' annotations does not match the number of rows in the DataFrame.\")\n",
    "\n",
    "    # Step 3: Create new annotations based on the reaction times in the DataFrame\n",
    "    for onset, choice_rt in zip(stimulus_onsets, df['choice_rt']):\n",
    "        late_threshold = 1.000\n",
    "        if not np.isnan(choice_rt):\n",
    "            new_onset = onset + choice_rt  # Calculate the new annotation onset time\n",
    "            if choice_rt < late_threshold:\n",
    "                seg.annotations.append(onset=new_onset, duration=0, description='Response')\n",
    "            else:\n",
    "                seg.annotations.append(onset=new_onset, duration=0, description='Late Response')\n",
    "        else:\n",
    "            new_onset = onset + 0.001  # Calculate the new annotation onset time\n",
    "            seg.annotations.append(onset=new_onset, duration=0, description='No Response')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# for i, an in enumerate(raw_segments[-1].annotations):\n",
    "#     if an['description'] in [*['Stimulus/S{:>3}'.format(stim) for stim in [20, 21, 22, 23, 48]], 'Response', 'No Response']:\n",
    "#         print(an)\n",
    "#     if i == 200:\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "53 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 53 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "55 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 55 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "50 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 50 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "43 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 43 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "47 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 47 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n",
      "Used Annotations descriptions: [np.str_('Response')]\n",
      "Not setting metadata\n",
      "48 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 48 events and 2501 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "## EXTRACT EPOCHS\n",
    "# Define the epochs\n",
    "tmin = -2.25  # Start of each epoch (e.g., 2250 ms before the event)\n",
    "tmax = 0.25   # End of each epoch (e.g., 250 ms after the event)\n",
    "\n",
    "epochs_list = []\n",
    "for seg in raw_segments:\n",
    "    events, event_id = mne.events_from_annotations(seg, event_id={'Response': 1, 'Late Response': 2, 'No Response': 3})\n",
    "    epochs_list.append(mne.Epochs(seg, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True))\n",
    "\n",
    "# Step 5: Inspect the epochs\n",
    "print(epochs_list[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: select epochs that have response, drop the rest according to annotation 'Late Response' / 'No Response'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}