{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.dataloader import load_subject_labels\n",
    "\n",
    "wd = '/Volumes/Guillaume EEG Project'\n",
    "epoch_data_path = os.path.join(wd, 'Berlin_Data/EEG/preprocessed/stim_epochs')\n",
    "raw_data_path = os.path.join(wd, 'Berlin_Data/EEG/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Volumes/Guillaume EEG Project/Berlin_Data/EEG/raw/101/proband_1.vhdr...\n",
      "Setting channel info structure...\n",
      "     response  confidence  choice_rt  correct  session  run\n",
      "0         1.0         1.0   0.905540      0.0        1    3\n",
      "1         1.0         1.0   0.454888      1.0        1    3\n",
      "2         1.0         1.0   0.943555      0.0        1    3\n",
      "3         1.0         1.0   0.823302      1.0        1    3\n",
      "4        -1.0         2.0   0.498823      1.0        1    3\n",
      "..        ...         ...        ...      ...      ...  ...\n",
      "325       1.0         1.0   0.801202      0.0        1    6\n",
      "326       1.0         1.0   0.609246      0.0        1    6\n",
      "327      -1.0         2.0   0.450043      1.0        1    6\n",
      "328       1.0         1.0   0.592723      0.0        1    6\n",
      "329       1.0         1.0   0.812557      1.0        1    6\n",
      "\n",
      "[330 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "subject_id = 101\n",
    "raws = [mne.io.read_raw_brainvision(os.path.join(raw_data_path, '{}/proband_{}.vhdr'.format(subject_id, subject_id-100)))]\n",
    "\n",
    "# raws = [mne.io.read_raw_brainvision(os.path.join(raw_data_path, '{}/{}.vhdr'.format(subject_id, subject_id)))]\n",
    "# for file in [os.path.join(raw_data_path, '{}/{}_{}.vhdr'.format(subject_id, subject_id, suffix)) for suffix in range(1, 7)]:\n",
    "#     if os.path.isfile(file):\n",
    "#         raw = mne.io.read_raw_brainvision(file)\n",
    "#         raws.append(raw)\n",
    "\n",
    "behav_data = load_subject_labels(raw_data_path, subject_id=subject_id)\n",
    "\n",
    "print(behav_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('New Segment/'), np.str_('Stimulus/S  3'), np.str_('Stimulus/S  4'), np.str_('Stimulus/S  5'), np.str_('Stimulus/S  6'), np.str_('Stimulus/S  7'), np.str_('Stimulus/S  8'), np.str_('Stimulus/S 10'), np.str_('Stimulus/S 11'), np.str_('Stimulus/S 12'), np.str_('Stimulus/S 20'), np.str_('Stimulus/S 21'), np.str_('Stimulus/S 22'), np.str_('Stimulus/S 23'), np.str_('Stimulus/S 25'), np.str_('Stimulus/S 28'), np.str_('Stimulus/S 29'), np.str_('Stimulus/S 40'), np.str_('Stimulus/S 41'), np.str_('Stimulus/S 46'), np.str_('Stimulus/S 48'), np.str_('Stimulus/S 50'), np.str_('Stimulus/S 56'), np.str_('Stimulus/S 64'), np.str_('Stimulus/S 73'), np.str_('Stimulus/S 76'), np.str_('Stimulus/S 88'), np.str_('Stimulus/S105'), np.str_('Stimulus/S150'), np.str_('Stimulus/S151')]\n",
      "7\n",
      "---------------1---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 92803 (92.8 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "3 trials\n",
      "\n",
      "---------------2---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 563827 (563.8 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n",
      "---------------3---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 452735 (452.7 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n",
      "---------------4---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 476881 (476.9 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n",
      "---------------5---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 444336 (444.3 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n",
      "---------------6---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 602126 (602.1 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n",
      "---------------7---------------\n",
      "<RawBrainVision | proband_1.eeg, 63 x 421917 (421.9 s), ~93 kB, data not loaded>\n",
      "2022-01-17 11:15:05.598816+00:00\n",
      "55 trials\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## SPLIT RAW INTO BLOCKS\n",
    "# Specify the annotation type you want to use for splitting\n",
    "split_annotation_type = 'Stimulus/S105'\n",
    "\n",
    "# Adjust events: keep only events within the cropped range\n",
    "# TODO: compare method below with pyEEG.preprocessing.ant2time_window !!!\n",
    "#   e.g.: do I have to divide start_sample and stop_sample with raw.info['sfreq']?\n",
    "# OTHER OPTION: can't I just modify annotations, without first converting to events?\n",
    "def adjust_events(raw, events):\n",
    "    \"\"\" Keep only events within the range of the raw data \"\"\"\n",
    "    start_sample = int(raw.first_samp)  # First sample of cropped data\n",
    "    stop_sample = int(raw.last_samp)  # Last sample of cropped data\n",
    "    valid_events = events[(events[:, 0] >= start_sample) & (events[:, 0] <= stop_sample)]\n",
    "\n",
    "    # Shift event onset times relative to new start\n",
    "    valid_events[:, 0] -= start_sample\n",
    "    return valid_events\n",
    "\n",
    "\n",
    "raw_segments = []\n",
    "for raw in raws:\n",
    "    # Find the onset times of the relevant annotations\n",
    "    split_onsets = [annot['onset']-1 for annot in raw.annotations if annot['description'] == split_annotation_type]\n",
    "\n",
    "    # Sort the onsets and add the start and end times of the raw object for splitting\n",
    "    split_onsets = split_onsets + [raw.times[-1]]\n",
    "\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    # Iterate over consecutive pairs of split points to create new raw segments\n",
    "    for start, end in zip(split_onsets[:-1], split_onsets[1:]):\n",
    "        raw_segment = raw.copy().crop(tmin=start, tmax=end, include_tmax=False)\n",
    "\n",
    "        adjusted_events = adjust_events(raw_segment, events)\n",
    "        adjusted_annotations = mne.annotations_from_events(adjusted_events, raw_segment.info['sfreq'], event_desc=dict((v, k) for k, v in event_id.items()))\n",
    "        raw_segment.set_annotations(adjusted_annotations)\n",
    "\n",
    "        # trial_n = pd.Series(raw_segment.annotations.description).value_counts()['Stimulus/S151']\n",
    "        # if trial_n == 55:\n",
    "        raw_segments.append(raw_segment)\n",
    "\n",
    "\n",
    "raw_segments = raw_segments[1:]\n",
    "# Now raw_segments is a list of mne.io.Raw objects split at the specified annotations\n",
    "print(len(raw_segments))\n",
    "\n",
    "for i, seg in enumerate(raw_segments):\n",
    "    print('---------------{}---------------'.format(i+1))\n",
    "    print(seg)\n",
    "    # print(pd.Series(seg.annotations.description).value_counts())\n",
    "    trial_n = pd.Series(seg.annotations.description).value_counts()['Stimulus/S151']\n",
    "    print(seg.info['meas_date'])\n",
    "    print('{} trials'.format(trial_n))\n",
    "    print('')\n",
    "\n",
    "    # mne.export.export_raw(\"segment{}.vhdr\".format(i), seg, fmt=\"brainvision\", overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# a_raw = raw_segments[0]\n",
    "# ann = a_raw.annotations.copy()\n",
    "# ann.onset -= a_raw.first_samp / a_raw.info['sfreq']\n",
    "# a_raw.set_annotations(ann)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from segment0.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment1.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment2.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment3.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment4.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment5.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment6.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from segment7.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m raw_segments_compare \u001B[38;5;241m=\u001B[39m [mne\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mread_raw_brainvision(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msegment\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.vhdr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i)) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(raw_segments))]\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[5], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m raw_segments_compare \u001B[38;5;241m=\u001B[39m [mne\u001B[38;5;241m.\u001B[39mio\u001B[38;5;241m.\u001B[39mread_raw_brainvision(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msegment\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.vhdr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(i)) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(raw_segments))]\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:747\u001B[0m, in \u001B[0;36mPyDBFrame.trace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;66;03m# if thread has a suspend flag, we suspend with a busy wait\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info\u001B[38;5;241m.\u001B[39mpydev_state \u001B[38;5;241m==\u001B[39m STATE_SUSPEND:\n\u001B[0;32m--> 747\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;66;03m# No need to reset frame.f_trace to keep the same trace function.\u001B[39;00m\n\u001B[1;32m    749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrace_dispatch\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py:144\u001B[0m, in \u001B[0;36mPyDBFrame.do_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_wait_suspend\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1155\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1152\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1154\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1155\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1170\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1167\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1169\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1170\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1174\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "raw_segments_compare = [mne.io.read_raw_brainvision(\"segment{}.vhdr\".format(i)) for i in range(len(raw_segments))]\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## CREATE NEW ANNOTATIONS FOR RESPONSE TIMES\n",
    "for i, seg in enumerate(raw_segments):\n",
    "    df = behav_data[behav_data['run'] == i + 1]\n",
    "\n",
    "    # Step 1: Extract the onsets of 'Stimulus/S 48' annotations\n",
    "    stimulus_onsets = [annot['onset'] for annot in seg.annotations if annot['description'] == 'Stimulus/S 48']\n",
    "    test1 = [annot['onset'] for annot in seg.annotations if annot['description'] == 'Stimulus/S150']\n",
    "    test2 = [annot['onset'] for annot in seg.annotations if annot['description'] == 'Stimulus/S151']\n",
    "    test3 = [annot['onset'] for annot in seg.annotations if annot['description'] == 'Stimulus/S 64']\n",
    "\n",
    "    i = 0\n",
    "    for a,b,c,d in zip(test1, test3, stimulus_onsets, test2):\n",
    "        print(a, b-a, c-a, d-a)\n",
    "        i += 1\n",
    "        if i == 5:\n",
    "            break\n",
    "\n",
    "\n",
    "    # Step 2: Ensure the number of onsets matches the number of rows in the DataFrame\n",
    "    if len(stimulus_onsets) != len(df):\n",
    "        raise ValueError(\"The number of 'Stimulus/S 48' ({}) annotations does not match the number of rows in the DataFrame ({}).\".format(len(stimulus_onsets), len(df)))\n",
    "\n",
    "    # Step 3: Create new annotations based on the reaction times in the DataFrame\n",
    "    for onset, choice_rt in zip(stimulus_onsets, df['choice_rt']):\n",
    "        late_threshold = 1.000\n",
    "        if not np.isnan(choice_rt):\n",
    "            new_onset = onset + choice_rt  # Calculate the new annotation onset time\n",
    "            if choice_rt < late_threshold:\n",
    "                seg.annotations.append(onset=new_onset, duration=0, description='Response')\n",
    "            else:\n",
    "                seg.annotations.append(onset=new_onset, duration=0, description='Late Response')\n",
    "        else:\n",
    "            new_onset = onset + 0.001  # Calculate the new annotation onset time\n",
    "            seg.annotations.append(onset=new_onset, duration=0, description='No Response')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i, an in enumerate(raw_segments[-1].annotations):\n",
    "#     if an['description'] in [*['Stimulus/S{:>3}'.format(stim) for stim in [20, 21, 22, 23, 48]], 'Response', 'No Response']:\n",
    "#         print(an)\n",
    "#     if i == 200:\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## EXTRACT EPOCHS\n",
    "# Define the epochs\n",
    "tmin = -1.0  # Start of each epoch (e.g., 2250 ms before the event)\n",
    "tmax = 2.5   # End of each epoch (e.g., 250 ms after the event)\n",
    "\n",
    "epochs_list = []\n",
    "for seg in raw_segments:\n",
    "    events, event_id = mne.events_from_annotations(seg, event_id={'Stimulus/S 64': 1}) #event_id={'Response': 1, 'Late Response': 2, 'No Response': 3})\n",
    "    epochs_list.append(mne.Epochs(seg, events, event_id=event_id, tmin=tmin, tmax=tmax, baseline=None, preload=True))\n",
    "\n",
    "# Step 5: Inspect the epochs\n",
    "print(epochs_list[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: select epochs that have response, drop the rest according to annotation 'Late Response' / 'No Response'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_compare = mne.io.read_raw_brainvision(\"first_half.vhdr\")\n",
    "pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}